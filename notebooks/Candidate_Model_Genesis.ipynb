{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "TvwryFt5GAZc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Bibliotecas de pré-processamento\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Bibliotecas de plotting\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
        "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
        "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feEoNQejIwql"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbkrbaoCIkS6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data/merged_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgVyLhgEpHC2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = df.drop(['record_id', 'idade_faixa'], axis=1)\n",
        "\n",
        "X_afetam_eficacia = df[['idade_diagnostico','primeiro_IMC','ultima_informacao_paciente', 'tempo_seguimento', 'recidiva_distancia', 'recidiva_regional', 'recidiva_local']]\n",
        "X_afetam_eficacia[['tempo_seguimento']] = StandardScaler().fit_transform(X_afetam_eficacia[['tempo_seguimento']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx0xfNKmL7Hh"
      },
      "outputs": [],
      "source": [
        "km = KMeans( n_clusters = 2, init = 'random', max_iter = 300, n_init = 100, random_state = 52 )\n",
        "km.fit( X_afetam_eficacia )\n",
        "y_km = km.predict( X_afetam_eficacia )\n",
        "df['eficacia_tratamento'] = y_km"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAoiQIkZ5hFx"
      },
      "outputs": [],
      "source": [
        "print(len(df.query(\"idade_diagnostico > 80 and ultima_informacao_paciente == 3 and eficacia_tratamento == 0\")))\n",
        "print(len(df.query(\"idade_diagnostico > 80 and ultima_informacao_paciente == 3 and eficacia_tratamento == 1\")))\n",
        "\n",
        "# Este é um sistema de classificação de tratamento em que \"0\" significa que o tratamento foi bom e \"1\" significa \n",
        "# que foi ruim. Há dois casos apresentados: no primeiro, uma pessoa idosa de 80 anos sobreviveu ao tratamento, indicando \n",
        "# que ele foi bom. No segundo caso, não houve sobreviventes entre as pessoas mais velhas e, portanto, o tratamento foi classificado \n",
        "# como negativo para essa faixa etária. É importante lembrar que a eficácia do tratamento pode variar de acordo com vários fatores e \n",
        "# que cada caso é único."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOoCCNVm7xWy"
      },
      "outputs": [],
      "source": [
        "df.query(\"idade_diagnostico < 30 and ultima_informacao_paciente == 0 and eficacia_tratamento == 1\")\n",
        "\n",
        "print(len(df.query(\"idade_diagnostico < 30 and ultima_informacao_paciente == 0 and eficacia_tratamento == 0\")))\n",
        "print(len(df.query(\"idade_diagnostico < 30 and ultima_informacao_paciente == 0 and eficacia_tratamento == 1\")))\n",
        "\n",
        "# Este modelo classifica o tratamento como bom (0) ou ruim (1). Ele foi testado em dois casos de mulheres com menos\n",
        "# de 30 anos: uma morreu e a outra sobreviveu. O modelo foi capaz de classificar corretamente cada caso, indicando que \n",
        "# tem uma boa capacidade de classificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH9ptuetMeYo"
      },
      "outputs": [],
      "source": [
        "df = df.query(\"tratamento == 0 or tratamento == 1\")[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSHRFU1Y0MKU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df = df.astype('float64')\n",
        "df = df[np.isfinite(df).all(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1KOsrCI-amh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['tratamento'], axis=1)\n",
        "y = df['tratamento']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 73)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3FcKLf2AcgZ"
      },
      "outputs": [],
      "source": [
        "!pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q0IcJ6eALuK"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL0vZaE32BTS"
      },
      "outputs": [],
      "source": [
        "models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk7ZjdM9mGOU"
      },
      "outputs": [],
      "source": [
        "classifiers = [AdaBoostClassifier(), \n",
        "               RandomForestClassifier(),\n",
        "               ExtraTreesClassifier(),\n",
        "               RidgeClassifierCV(), \n",
        "               LinearSVC(),\n",
        "               LogisticRegression(), \n",
        "               SVC(), \n",
        "               LGBMClassifier(),\n",
        "               LinearDiscriminantAnalysis(), \n",
        "               RidgeClassifier(), \n",
        "               CalibratedClassifierCV(), \n",
        "               XGBClassifier(),\n",
        "               NearestCentroid(), \n",
        "               SGDClassifier(), \n",
        "               BaggingClassifier(),\n",
        "               BernoulliNB(),\n",
        "               PassiveAggressiveClassifier(), \n",
        "               Perceptron(),\n",
        "               NuSVC(), \n",
        "               DecisionTreeClassifier(), \n",
        "               KNeighborsClassifier(),\n",
        "               LabelSpreading(),\n",
        "               LabelPropagation(), \n",
        "               ExtraTreeClassifier(),\n",
        "               GaussianNB(),\n",
        "               DummyClassifier(),\n",
        "               QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for classifier in classifiers:\n",
        "    clf = classifier.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    precisions.append(precision_score(y_test, y_pred))\n",
        "    recalls.append(recall_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6FjkPUxoG4o"
      },
      "outputs": [],
      "source": [
        "models['Precision'] = 0\n",
        "models['Recall'] = 0   \n",
        "\n",
        "for i in range(0, len(precisions)):\n",
        "  models['Precision'].iloc[i] = precisions[i]\n",
        "  models['Recall'].iloc[i] = recalls[i]\n",
        "\n",
        "models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0jsLs0YynzI"
      },
      "outputs": [],
      "source": [
        "clf = AdaBoostClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GridSearch"
      ],
      "metadata": {
        "id": "cRZIHegZl_-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "\n",
        "params = {\n",
        "          'estimator':[None, DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)],\n",
        "          'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "          'learning_rate': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "          'algorithm': ['SAMME', 'SAMME.R']\n",
        "          }\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "model = grid_search.best_estimator_\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')"
      ],
      "metadata": {
        "id": "lyOcjiCPmCgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "params = {\n",
        "          'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "          'criterion': ['gini','entropy','log_loss'],\n",
        "          'max_depth': [5,10,15,20,25],\n",
        "          'min_samples_split':[1,2,3,4],\n",
        "          'min_samples_leaf': [1,2,3,4],\n",
        "          'min_weight_fraction_leaf':[0,1,2],\n",
        "          'max_features':['sqrt','log2',None],\n",
        "          'max_leaf_nodes': [None, 1, 2],\n",
        "          'min_impurity_decrease': [0, 1, 2],\n",
        "          'bootstrap': [True, False],\n",
        "          'oob_score': [True, False],\n",
        "          'n_jobs': [None, 1, -1],\n",
        "          'verbose': [0, 1, 2],\n",
        "          'warm_start': [True, False], \n",
        "          'class_weight': ['balanced', 'balanced_subsample'],\n",
        "          'ccp_alpha': [0, 1]\n",
        "          }\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "print(grid_search.score(X_test, y_test))\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')"
      ],
      "metadata": {
        "id": "C4XF3daPmEvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LGBMClassifier()\n",
        "\n",
        "params = {\n",
        "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
        "    'num_leaves': [20, 30, 40],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'min_child_samples': [5, 10, 15],\n",
        "    'subsample': [0.5, 0.7, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
        "    'reg_alpha': [0, 0.1, 1.0],\n",
        "    'reg_lambda': [0, 0.1, 1.0],\n",
        "    'importance_type': ['split', 'gain']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "print(grid_search.score(X_test, y_test))\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')"
      ],
      "metadata": {
        "id": "PBJKlkDMmGka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RandomizedSearchCV"
      ],
      "metadata": {
        "id": "bYz9LY7iY8fi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h_Io0JLsqmh"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "\n",
        "params = {\n",
        "          'estimator':[None, DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)],\n",
        "          'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "          'learning_rate': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "          'algorithm': ['SAMME', 'SAMME.R']\n",
        "          }\n",
        "\n",
        "model_random = RandomizedSearchCV(estimator=model, param_distributions=params, cv=5, n_iter=50)\n",
        "\n",
        "model_random.fit(X_train, y_train)\n",
        "\n",
        "print(model_random.best_params_)\n",
        "print(model_random.best_score_)\n",
        "print(model_random.score(X_test, y_test))\n",
        "\n",
        "y_pred = model_random.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfEMoFBj3i61"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "random_grid = {\n",
        "            'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "            'max_depth': [5,10,15,20,25,None],\n",
        "            'min_samples_split':[2,3,4,5],\n",
        "            'min_samples_leaf': [1,2,3,4],\n",
        "            'min_weight_fraction_leaf':[0,1,2],\n",
        "            'max_features':['sqrt','log2',None],\n",
        "            'max_leaf_nodes': [None, 1, 2],\n",
        "            'min_impurity_decrease': [0, 1, 2],\n",
        "            'bootstrap': [True, False],\n",
        "            'oob_score': [True, False],\n",
        "            'n_jobs': [None, 1, -1],\n",
        "            'verbose': [0, 1, 2],\n",
        "            'warm_start': [True, False],\n",
        "            'ccp_alpha': [0, 1]\n",
        "               }\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "print(rf_random.best_params_)\n",
        "print(rf_random.best_score_)\n",
        "print(rf_random.score(X_test, y_test))\n",
        "\n",
        "y_pred = rf_random.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LGBMClassifier()\n",
        "\n",
        "params = {\n",
        "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
        "    'num_leaves': [20, 30, 40],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'min_child_samples': [5, 10, 15],\n",
        "    'subsample': [0.5, 0.7, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
        "    'reg_alpha': [0, 0.1, 1.0],\n",
        "    'reg_lambda': [0, 0.1, 1.0],\n",
        "    'importance_type': ['split', 'gain']\n",
        "}\n",
        "\n",
        "grid_search = RandomizedSearchCV(estimator=model, param_distributions=params, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "print(grid_search.score(X_test, y_test))\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')"
      ],
      "metadata": {
        "id": "YNHR67mWZCFZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}