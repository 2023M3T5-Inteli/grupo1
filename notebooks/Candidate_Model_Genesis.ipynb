{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TvwryFt5GAZc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Bibliotecas de pré-processamento\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Bibliotecas de plotting\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
        "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
        "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feEoNQejIwql",
        "outputId": "10f07914-63eb-431d-db1e-e7eb74332e03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wbkrbaoCIkS6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data/merged_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgVyLhgEpHC2",
        "outputId": "2137c871-0045-4c96-fef5-0c0504428548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6de22f19c6fc>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_afetam_eficacia[['tempo_seguimento']] = StandardScaler().fit_transform(X_afetam_eficacia[['tempo_seguimento']])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = df.drop(['record_id', 'idade_faixa'], axis=1)\n",
        "\n",
        "X_afetam_eficacia = df[['idade_diagnostico','primeiro_IMC','ultima_informacao_paciente', 'tempo_seguimento', 'recidiva_distancia', 'recidiva_regional', 'recidiva_local']]\n",
        "X_afetam_eficacia[['tempo_seguimento']] = StandardScaler().fit_transform(X_afetam_eficacia[['tempo_seguimento']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kx0xfNKmL7Hh"
      },
      "outputs": [],
      "source": [
        "km = KMeans( n_clusters = 2, init = 'random', max_iter = 300, n_init = 100, random_state = 52 )\n",
        "km.fit( X_afetam_eficacia )\n",
        "y_km = km.predict( X_afetam_eficacia )\n",
        "df['eficacia_tratamento'] = y_km"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAoiQIkZ5hFx",
        "outputId": "f437bcb0-c226-4eae-963b-f61b28f38a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "38\n"
          ]
        }
      ],
      "source": [
        "print(len(df.query(\"idade_diagnostico > 80 and ultima_informacao_paciente == 3 and eficacia_tratamento == 0\")))\n",
        "print(len(df.query(\"idade_diagnostico > 80 and ultima_informacao_paciente == 3 and eficacia_tratamento == 1\")))\n",
        "\n",
        "# Este é um sistema de classificação de tratamento em que \"0\" significa que o tratamento foi bom e \"1\" significa \n",
        "# que foi ruim. Há dois casos apresentados: no primeiro, uma pessoa idosa de 80 anos sobreviveu ao tratamento, indicando \n",
        "# que ele foi bom. No segundo caso, não houve sobreviventes entre as pessoas mais velhas e, portanto, o tratamento foi classificado \n",
        "# como negativo para essa faixa etária. É importante lembrar que a eficácia do tratamento pode variar de acordo com vários fatores e \n",
        "# que cada caso é único."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOoCCNVm7xWy",
        "outputId": "9eebcf1a-ee33-4733-dc51-f4bc493474da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "df.query(\"idade_diagnostico < 30 and ultima_informacao_paciente == 0 and eficacia_tratamento == 1\")\n",
        "\n",
        "print(len(df.query(\"idade_diagnostico < 30 and ultima_informacao_paciente == 0 and eficacia_tratamento == 0\")))\n",
        "print(len(df.query(\"idade_diagnostico < 30 and ultima_informacao_paciente == 0 and eficacia_tratamento == 1\")))\n",
        "\n",
        "# Este modelo classifica o tratamento como bom (0) ou ruim (1). Ele foi testado em dois casos de mulheres com menos\n",
        "# de 30 anos: uma morreu e a outra sobreviveu. O modelo foi capaz de classificar corretamente cada caso, indicando que \n",
        "# tem uma boa capacidade de classificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HH9ptuetMeYo"
      },
      "outputs": [],
      "source": [
        "df = df.query(\"tratamento == 0 or tratamento == 1\")[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OSHRFU1Y0MKU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df = df.astype('float64')\n",
        "df = df[np.isfinite(df).all(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w1KOsrCI-amh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['tratamento'], axis=1)\n",
        "y = df['tratamento']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 73)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3FcKLf2AcgZ",
        "outputId": "1f9c74c5-0288-4a6c-d436-317969d2c335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from lazypredict) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from lazypredict) (8.1.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.9/dist-packages (from lazypredict) (3.3.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (from lazypredict) (1.7.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from lazypredict) (1.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from lazypredict) (1.4.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from lazypredict) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lightgbm->lazypredict) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from lightgbm->lazypredict) (1.22.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm->lazypredict) (0.40.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->lazypredict) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->lazypredict) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->lazypredict) (1.16.0)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q0IcJ6eALuK",
        "outputId": "7d0c7fcc-19bd-469a-8108-e15fa58fc443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2/29 [00:00<00:10,  2.67it/s]"
          ]
        }
      ],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL0vZaE32BTS"
      },
      "outputs": [],
      "source": [
        "models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk7ZjdM9mGOU"
      },
      "outputs": [],
      "source": [
        "classifiers = [AdaBoostClassifier(), \n",
        "               RandomForestClassifier(),\n",
        "               ExtraTreesClassifier(),\n",
        "               RidgeClassifierCV(), \n",
        "               LinearSVC(),\n",
        "               LogisticRegression(), \n",
        "               SVC(), \n",
        "               LGBMClassifier(),\n",
        "               LinearDiscriminantAnalysis(), \n",
        "               RidgeClassifier(), \n",
        "               CalibratedClassifierCV(), \n",
        "               XGBClassifier(),\n",
        "               NearestCentroid(), \n",
        "               SGDClassifier(), \n",
        "               BaggingClassifier(),\n",
        "               BernoulliNB(),\n",
        "               PassiveAggressiveClassifier(), \n",
        "               Perceptron(),\n",
        "               NuSVC(), \n",
        "               DecisionTreeClassifier(), \n",
        "               KNeighborsClassifier(),\n",
        "               LabelSpreading(),\n",
        "               LabelPropagation(), \n",
        "               ExtraTreeClassifier(),\n",
        "               GaussianNB(),\n",
        "               DummyClassifier(),\n",
        "               QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for classifier in classifiers:\n",
        "    clf = classifier.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    precisions.append(precision_score(y_test, y_pred))\n",
        "    recalls.append(recall_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6FjkPUxoG4o"
      },
      "outputs": [],
      "source": [
        "models['Precision'] = 0\n",
        "models['Recall'] = 0   \n",
        "\n",
        "for i in range(0, len(precisions)):\n",
        "  models['Precision'].iloc[i] = precisions[i]\n",
        "  models['Recall'].iloc[i] = recalls[i]\n",
        "\n",
        "models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0jsLs0YynzI"
      },
      "outputs": [],
      "source": [
        "clf = AdaBoostClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRZIHegZl_-S"
      },
      "source": [
        "##GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyOcjiCPmCgD"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "\n",
        "params = {\n",
        "          'estimator':[None, DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)],\n",
        "          'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "          'learning_rate': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "          'algorithm': ['SAMME', 'SAMME.R'],\n",
        "           'random_state': [73]\n",
        "          }\n",
        "\n",
        "grid_searchAda = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
        "\n",
        "grid_searchAda.fit(X_train, y_train)\n",
        "\n",
        "print(grid_searchAda.best_params_)\n",
        "print(grid_searchAda.best_score_)\n",
        "print(grid_searchAda.score(X_test, y_test))\n",
        "\n",
        "# {'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=2), 'learning_rate': 0.1, 'n_estimators': 500, 'random_state': 73}\n",
        "# 0.6920594714828493\n",
        "# 0.6695371367061357"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4XF3daPmEvr"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "params = {\n",
        "          'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "          'max_depth': [5,10,15,20,25],\n",
        "          'max_features':['sqrt','log2',None],\n",
        "          'random_state': [73]\n",
        "          }\n",
        "\n",
        "grid_searchRF = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
        "\n",
        "grid_searchRF.fit(X_train, y_train)\n",
        "\n",
        "print(grid_searchRF.best_params_)\n",
        "print(grid_searchRF.best_score_)\n",
        "print(grid_searchRF.score(X_test, y_test))\n",
        "\n",
        "# {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100, 'random_state': 73}\n",
        "# 0.6911463266674472\n",
        "# 0.6598493003229279"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBJKlkDMmGka"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LGBMClassifier()\n",
        "\n",
        "params = {\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'random_state': [73]\n",
        "}\n",
        "\n",
        "grid_searchLGBM = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
        "\n",
        "grid_searchLGBM.fit(X_train, y_train)\n",
        "\n",
        "print(grid_searchLGBM.best_params_)\n",
        "print(grid_searchLGBM.best_score_)\n",
        "print(grid_searchLGBM.score(X_test, y_test))\n",
        "\n",
        "# {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50, 'random_state': 73}\n",
        "# 0.6842125988442014\n",
        "# 0.6727664155005382"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYz9LY7iY8fi"
      },
      "source": [
        "##RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h_Io0JLsqmh"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "\n",
        "params = {\n",
        "          'estimator':[None, DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)],\n",
        "          'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "          'learning_rate': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "          'algorithm': ['SAMME', 'SAMME.R'],\n",
        "          'random_state': [73]\n",
        "          }\n",
        "\n",
        "randomizedSearchAda = RandomizedSearchCV(estimator=model, param_distributions=params, cv=5, n_iter=50)\n",
        "\n",
        "randomizedSearchAda.fit(X_train, y_train)\n",
        "\n",
        "print(randomizedSearchAda.best_params_)\n",
        "print(randomizedSearchAda.best_score_)\n",
        "print(randomizedSearchAda.score(X_test, y_test))\n",
        "\n",
        "# {'random_state': 73, 'n_estimators': 100, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2), 'algorithm': 'SAMME'}\n",
        "# 0.6897510669320249\n",
        "# 0.6706135629709364"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfEMoFBj3i61"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "random_grid = {\n",
        "          'n_estimators': [50, 150, 100, 200, 300, 400, 500],\n",
        "          'max_depth': [5,10,15,20,25],\n",
        "          'max_features':['sqrt','log2',None],\n",
        "          'random_state': [73]\n",
        "               }\n",
        "\n",
        "randomizedSearchRF = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "randomizedSearchRF.fit(X_train, y_train)\n",
        "\n",
        "print(randomizedSearchRF.best_params_)\n",
        "print(randomizedSearchRF.best_score_)\n",
        "print(randomizedSearchRF.score(X_test, y_test))\n",
        "\n",
        "# {'random_state': 73, 'n_estimators': 150, 'max_features': 'sqrt', 'max_depth': 10}\n",
        "# 0.6809787626962143\n",
        "# 0.6641550053821313"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNHR67mWZCFZ"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LGBMClassifier()\n",
        "\n",
        "params = {\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'random_state': [73]\n",
        "}\n",
        "\n",
        "randomizedSearchLGBM = RandomizedSearchCV(estimator=model, param_distributions=params, cv=5)\n",
        "\n",
        "randomizedSearchLGBM.fit(X_train, y_train)\n",
        "\n",
        "print(randomizedSearchLGBM.best_params_)\n",
        "print(randomizedSearchLGBM.best_score_)\n",
        "print(randomizedSearchLGBM.score(X_test, y_test))\n",
        "\n",
        "# {'random_state': 73, 'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.05}\n",
        "# 0.6842125988442014\n",
        "# 0.6727664155005382"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}